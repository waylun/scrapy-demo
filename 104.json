[
{"date": "3/14", "title": "網頁分析工程師", "link": "www.104.com.tw/job/7i5jf?jobsource=index_s", "company": "鴻璟科技股份有限公司", "intro": "新竹市 經歷不拘 碩士", "desc": "職務內容包含以下一到數項： - 分析網頁來源與內容，提供網頁流量分級、分類與資訊安全解析。 - 開發、操作、維護自然語言處理(Natural language processing, NLP)、資料工程(Data engineering)、人工智慧(Artificial intelligence, AI)分析系統。 - 設計、管理分析資料庫。 - 釣魚網站與惡意網頁分析。 - 研究各種駭客攻擊手法、病毒與資安議題。", "tags": [], "detail": ["職務內容包含以下一到數項：- 分析網頁來源與內容，提供網頁流量分級、分類與資訊安全解析。- 開發、操作、維護自然語言處理(Natural language processing, NLP)、資料工程(Data engineering)、人工智慧(Artificial intelligence, AI)分析系統。- 設計、管理分析資料庫。- 釣魚網站與惡意網頁分析。- 研究各種駭客攻擊手法、病毒與資安議題。"]},
{"date": "8/03", "title": "Data Engineer", "link": "www.104.com.tw/job/7nqiz?jobsource=index_s", "company": "台灣積體電路製造股份有限公司(台積電)", "intro": "新竹市 經歷不拘 大學", "desc": "Scrapy and BeautifulSoup •Strong working knowledge of relational data management, including extracting, transforming, loading,", "tags": ["上市上櫃"], "detail": ["【本職缺僅接受台積電官方網站投遞】請至台積電官方網站投遞個人履歷表，此職缺履歷登錄網址:https://careers.tsmc.com/careers/JobDetail?jobId=518&source=104Description Job Responsibility: The responsibilities of this role include developing data pipelines (collection, extraction, processing, representation, management) for data scientists focused on developing intelligence from structured (transactional) data and unstructured (e.g., text) data with Artificial Intelligence (AI)-enabled analytics procedures. Ideal candidates would have either a Bachelor’s or Master’s degree in computer science, information systems, information science or related fields.  Qualifications Job Requirement: Minimum Technical Qualifications:•Strong working knowledge of Python (with Jupyter, PyCharm, or similar environment), GitHub, and Markdown•Experience in connecting to REST API endpoints, particularly in parsing data in JSON and XML formats•Experience in developing web crawlers to collect data from web pages using tools such as Scrapy and BeautifulSoup•Strong working knowledge of relational data management, including extracting, transforming, loading, and querying from MySQL databases•Knowledge of server-based front-end/UI technologies, including HTML, CSS, and PHP"]},
{"date": "1/19", "title": "大型知識探索工程師（LLM Discovery Engineer）", "link": "www.104.com.tw/job/7tkwm?jobsource=index_s", "company": "Taiwan AI Labs_雅婷智慧股份有限公司", "intro": "台北市大同區 經歷不拘 大學", "desc": "Git、Linux與Docker等技術。 2.充分熟悉HTML結構，具備解析網頁交換資料的順序步驟能力。　 3.熟悉網路大型知識平台套件與框架，如Scrapy、Puppeteer、Selenium等。 4.喜愛研究和分享新技術，具有獨立調查和實踐能", "tags": ["距捷運中山站約330公尺"], "detail": ["Taiwan AI Labs is a dynamic startup environment offering exceptional career development opportunities. We invite talented professionals to join us in advancing genomics AI research and are seeking results-driven and highly organized individuals with a strong leadership mindset to plan, execute and manage clinical and genomic research service projects.Responsibilities【工作內容】1.建立自動化工具探索、獲取媒體與社群平台資訊 ，如YouTube、TikTok、 Weibo    Facebook和Twitter 。　2.參與大型知識平台架構設計，爭取最高速率獲取完整正確資料。　3.設計與調整大型知識平台數據整合機制，自動驗證大型知識平台數據正確性。4.確保大型知識平台服務效率與穩定性。5.與其他後端工程師協作完成 API 功能和攥寫文檔。　6.參與 ETL 設計與實作。Required Skills【具備條件】1.熟悉Python、Git、Linux與Docker等技術。2.充分熟悉HTML結構，具備解析網頁交換資料的順序步驟能力。　3.熟悉網路大型知識平台套件與框架，如Scrapy、Puppeteer、Selenium等。4.喜愛研究和分享新技術，具有獨立調查和實踐能力。Experience in at least one of the following area is required【加分條件】1.具備Kubernetes 相關經驗。2.具備自動化測試經驗。3.具備估算大型知識平台效率並提解出優化建議。"]},
{"date": "3/08", "title": "資深數據工程師 / Senior Data Engineer", "link": "www.104.com.tw/job/5o7vg?jobsource=index_s", "company": "大數據股份有限公司", "intro": "台北市中山區 3年以上 大學", "desc": "交換資料的順序步驟　 - 熟悉Git - 熟悉Linux, Docker - 熟悉網路爬蟲套件與框架(如Scrapy, Puppeteer, Selenium, Playwright) - 喜愛研究、討論、分享與學習新技術、有獨立survey與實作", "tags": ["員工70人", "距捷運行天宮站約470公尺"], "detail": ["本公司為專業社群資料分析廠商，主要產品有《KEYPO大數據關鍵引擎》，透過深度學習在巨量社群資料中洞察網路口碑。本職務需熟悉web crawling techniques, automation, data storage, and data pipelines:【工作內容】- 設計爬蟲架構，提升抓取的效率和品質- 維護爬蟲可靠度與可用率　- 設計/優化資料管線與儲存架構　　- 參與ETL設計與實作【必要技能】- 熟悉Python語法- 充分了解HTML結構，能解析網頁交換資料的順序步驟　- 熟悉Git- 熟悉Linux, Docker- 熟悉網路爬蟲套件與框架(如Scrapy, Puppeteer, Selenium, Playwright)- 喜愛研究、討論、分享與學習新技術、有獨立survey與實作能力　【加分條件】 - 具有自動化測試經驗- 在生產環境中使用CI/CD- 熟悉容器調度工具如Docker Swarm- 具有Agile / Scrum開發經驗- 有程式重構、大型專案架構設計之經驗"]},
{"date": "3/14", "title": "Software Engineer, Crawler 軟體工程師", "link": "www.104.com.tw/job/828px?jobsource=index_s", "company": "香港商香港球鞋團隊有限公司", "intro": "台北市中正區 4年以上 大學", "desc": "台。 2. 熟悉使用 Requests、beautifulsoup4、 Scrapy 等其中一種lib或者框架進行網絡爬蟲。 3. 熟練使用 Python 編程。如能靈活使用Python的多線程和多進程加速計算為加分項。 4. 對 Mysql、", "tags": ["月薪70,000元以上", "員工100人", "距捷運善導寺站約450公尺"], "detail": ["KICKS CREW is one of the fastest growing athletic footwear and apparel ecommerce platforms. Our engineers develop the state of the art technologies to transform how customers experience, explore and shop.Our platform needs to handle product and customer data at a massive scale. We are looking for software engineers who can apply their expertise from different areas to maintain and develop our system to support the rapid growth.You will be working in a cross functional team with Backend, Frontend and/or Mobile Engineers to develop our e-commerce platform. We need our engineers to have a broad set of technical and communication skills to be a valuable team member. We hope you can join us and shape the landscape of next-generation ecommerce.At Kicks Crew, you will be joining a growing, fast-paced team with strong startup spirits. We are looking for general programming talents with strong focus to fast response time.Scripting language such as Python / Typescript will be part of our daily, and we welcome proposals for new tooling stacks. *** 軟體工程師主要負責數據爬取項目, 包括：1. 使用爬蟲工具/框架從網站爬取信息； 2. 研究並開發分佈式爬蟲軟件以及數據收集系統； 3. 數據爬取過程中確保數據質量，不斷優化爬蟲策略； 4. 分析數據深入解讀有關顧客行為、市場動態等信息；任職要求： 1. 熟悉使用 Flask、Django 等其中一種框架構建 Python 後端平台。2. 熟悉使用 Requests、beautifulsoup4、 Scrapy 等其中一種lib或者框架進行網絡爬蟲。3. 熟練使用 Python 編程。如能靈活使用Python的多線程和多進程加速計算為加分項。4. 對 Mysql、MongoDB 有使用經驗。 5. 有使用雲計算平台（例如: Google Cloud）經驗的人士，會優先考慮，包括對象存儲、虛擬機、serverless函數等。Main responsibilities of the position include:1. Crawling information from websites using web scraping tools/frameworks.2. Researching and developing distributed web crawling software and data collection systems.3. Ensuring data quality during the crawling process and continuously optimizing web crawling strategies.4. Analyzing data to gain insights into customer behavior, market trends, and other relevant information.Job requirements:1. Proficiency in building Python backend platforms using frameworks such as Flask or Django.2. Familiar with web scraping libraries/frameworks such as Requests, BeautifulSoup4, or Scrapy.3. Strong programming skills in Python with in depth knowledge on multithreading and multiprocessing capabilities.4. Experience with MySQL and MongoDB databases.5. Candidates with experience using cloud computing platforms (e.g., Google Cloud) is a plus, including knowledge of object storage, virtual machines, serverless functions, etc."]},
{"date": "3/14", "title": "數據工讀生 (長期工讀)", "link": "www.104.com.tw/job/89q9w?jobsource=index_s", "company": "大數據股份有限公司", "intro": "台北市中山區 經歷不拘 專科", "desc": "用經驗 - 有爬蟲套件與框架(如Scrapy, Puppeteer, Selenium, Playwright)使用經驗 - 有Linux, Docker使用經驗", "tags": ["時薪183元", "員工70人", "距捷運行天宮站約220公尺"], "detail": ["【工作內容】- 爬蟲程式維護，提升可靠度與可用率- 爬蟲相關帳號維護- 主管交辦事項【必要技能】- 熟悉Python語法- 熟悉HTML結構，能使用套件（如beautiful soup）解析網頁資料　【加分條件】- 有Git使用經驗- 有爬蟲套件與框架(如Scrapy, Puppeteer, Selenium, Playwright)使用經驗- 有Linux, Docker使用經驗"]},
{"date": "3/18", "title": "資料工程師", "link": "www.104.com.tw/job/6skax?jobsource=index_s", "company": "台盈資訊科技有限公司", "intro": "台北市松山區 1年以上 大學", "desc": "職務內容： 1. 開發和維護數據處理工具，以支持我們的數據處理和分析需求。 2. 使用SQL Server和PostgreSQL等數據庫系統進行數據存儲和查詢操作。 3. 使用Scrapy爬蟲框架從網站和API中提取數據。 4. 使用Pandas", "tags": ["員工60人"], "detail": ["職務內容：1. 開發和維護數據處理工具，以支持我們的數據處理和分析需求。2. 使用SQL Server和PostgreSQL等數據庫系統進行數據存儲和查詢操作。3. 使用Scrapy爬蟲框架從網站和API中提取數據。4. 使用Pandas進行數據處理、轉換和分析。5. 優化數據處理流程，提高效率和性能。6. 在Ubuntu和Windows作業系統上進行開發和測試。7. 使用GitHub進行版本控制，協作開發和代碼審查。8. 與團隊成員合作，協助解決數據相關的問題。9. 跟蹤數據處理工作的進展，確保項目按時交付。必備技能：1. 熟練使用Python進行開發，具有豐富的Python編程經驗。2. 熟悉SQL Server和PostgreSQL等數據庫系統，能夠進行數據存儲和查詢操作。3. 具備Scrapy爬蟲框架的開發經驗，能夠從網站和API中爬取數據。4. 熟練使用Pandas進行數據處理、轉換和分析。5. 具備良好的數據處理和數據分析技能，能夠解決數據相關的挑戰。6. 具備自我學習和解決問題的能力，能夠跟蹤新技術和工具的發展。7. 能夠在Ubuntu和Windows作業系統上進行開發和測試。8. 具備良好的團隊合作和溝通能力。9. 熟悉GitHub的版本控制流程，能夠進行協作開發和代碼審查。"]},
{"date": "3/14", "title": "資深數據工程師 Senior Data Engineer/Data Architect (Data Science & AI Team)", "link": "www.104.com.tw/job/7yr1c?jobsource=index_s", "company": "鴻海精密工業股份有限公司", "intro": "新北市土城區 經歷不拘 碩士", "desc": "Scrapy. (2)Accessing data from REST APIs, particularly in parsing data in disparate formats such as JSON and XML, and", "tags": ["上市上櫃"], "detail": ["<About the job> As the Senior Data Engineer or Data Architect, you'll join the various advanced Data Science & AI Projects in the corporate headquarters. As well as developing intelligent applications via related AI and Big Data Analytics Technology for digital transformation, you will have plenty of opportunities to develop emerging applications based on different use cases and expand your tech skillset in this world-class company (Fortune Global 500, 20th).<Job Description>*Type 1：Senior Data EngineerResponsible for acquiring data using API, Web scraping, or other data accessing protocol/scripting and developing the ETL data pipelines, and the data aggregation systems. Using software development experience to design and build high-performance automated systems. As below:1. Data Processing(1)Data ETL(Extracting/Transforming/Loading) process engineering and querying from relational data management(such as SQL Script).(2)Building systematic data quality processes and checks to ensure data quality and accuracy.(3)Solid coding experience in Python or Java.2. Data Pipeline Development(1)Develops a data integration process, including creating scalable data pipelines and building out data services/data APIs.(2)Create a data processing automation and monitoring mechanism by optimizing the data pipeline process. (3)Experience with dataflow/workflow/management tools, such as Apache Nifi, Apache Airflow, Azkaban, etc., is preferred.3. Data Crawling(1)Build scalable tools that automate web crawling, scraping, and data aggregation from various web pages using frameworks such as Scrapy.(2)Accessing data from REST APIs, particularly in parsing data in disparate formats such as JSON and XML, and developing automated engineering. (3) (Nice to Have) Knowledge of server-based front-end/UI technologies, including Vue/React and HTML/CSS, is preferred.*Type 2：Data ArchitectResponsible for designing, implementing, and maintaining scalable and reusable system architectures/data architectures for complex data structures and large data in data science and AI projects. As below:1. Data Schema Design(1)Collaborate with the team to design DB/Table Schema and Data Schema.(2)Consolidate the requirements and use data engineering tech to design and implement a robust Data Mart. (3)Experience handling all kinds of structured/semi-structured/unstructured data and streaming data is preferred.(4)Hands-on experience with Dimensional Data Modeling(Column-based data warehouse) or NoSQL Schema design.2. Data Platform Architecture(1)Design and build data infrastructure/platform components to support complex data pipelines ingesting various data from multiple internal and external data sources and processing.(2)Familiar with Big Data frameworks and processing technologies, ex: Hadoop, Apache Spark, NoSQL ...etc.(3)Familiar with AZURE or AWS cloud data services(hands-on experience with cloud infrastructure will be a plus)(4)Familiarity with the Linux OS environment, the Shell Scripting, and infrastructure knowledge. (5)(Nice to Have)Experience with declarative infrastructure/container technologies, such as Docker and Kubernetes (k8s/k3s). (Nice to Have)."]}
]